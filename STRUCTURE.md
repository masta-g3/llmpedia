# LLMpedia Project Structure

## Main Files

- `app.py`: The main Streamlit application file that contains the UI and application logic
- `README.md`: Project documentation and setup instructions
- `requirements.txt`: Python dependencies for the project
- `Procfile`: Configuration for deployment on platforms like Heroku (primarily relevant if deploying outside Streamlit Cloud)
- `.env.template` & `.env`: Environment variable configuration for local development
- `STRUCTURE.md`: This file, describing the project layout
- `PLANNING.md`: Temporary file for planning complex tasks
- `CHANGES.md`: Log of deviations from initial implementation plans

## Directories

- `utils/`: Utility functions and modules for the application
  - `plots.py`: Visualization functions for creating charts and plots (e.g., publication trends, topic maps)
  - `streamlit_utils.py`: Utility functions specific to Streamlit UI components (e.g., custom pagination, styling helpers)
  - `app_utils.py`: General utility functions for the application logic (e.g., data formatting, helper calculations)
  - `styling.py`: CSS and styling functions, including custom CSS injection
  - `db/`: Database-related utilities
    - `db_utils.py`: Lower-level database connection and query execution helpers (consider merging or refactoring if overlap with `db.py`)
    - `db.py`: Consolidated database access functions abstracting queries for papers, embeddings, tweets, repositories, etc. This is the primary interface for fetching data for the UI.
    - `logging_db.py`: Functions specifically for logging user interactions or application events to the database.
  - `instruct.py`: Functions for interacting with external LLM APIs (OpenAI, Anthropic, etc.) used in the chat feature.
  - `pydantic_objects.py`: Pydantic models used for data validation, especially for data fetched from the database or external APIs.
  - `prompts.py`: Predefined prompt templates used for generating queries or instructions for the LLMs in `instruct.py`.
- `notebooks/`: Jupyter notebooks used for experimentation, data analysis, or one-off tasks during development. Not part of the core application runtime.
- `components/`: Custom Streamlit components
- `deployment/`: Configuration files and guides for deployment
  - `digitalocean/`: Files specific to DigitalOcean deployment
    - `nginx_streamlit.conf`: Nginx configuration template
    - `streamlit_app.service`: Systemd service file template
    - `DEPLOY_DIGITALOCEAN.md`: Step-by-step deployment guide for DigitalOcean

## Key Features

### Main Application (app.py)

The application is organized into tabs:

1. **üì∞ Main Page**: Landing page showing recent paper statistics, trending topics, and a featured paper
   - Recent papers (1-day and 7-day statistics)
   - Category distribution visualization
   - Trending topics based on paper titles
   - Featured paper (most cited or recent)
   - Quick navigation buttons

2. **üßÆ Release Feed**: Grid or table view of papers with pagination
   - Supports both grid and table views
   - Paginated navigation

3. **üó∫Ô∏è Statistics & Topics**: Visualizations of publication trends and topics
   - Publication count charts (daily and cumulative)
   - Topic model map for exploring paper clusters

4. **üîç Paper Details**: Detailed view of a specific paper
   - Search by arXiv code
   - Detailed paper information and summaries

5. **ü§ñ Online Research**: AI chat interface for querying paper data
   - Natural language questions about LLM research
   - Response settings for customization
   - Source citations and references

6. **‚öôÔ∏è Links & Repositories**: Related repositories and resources
   - Filterable list of repositories
   - Visualization of repositories by category

7. **üóû Weekly Report**: Weekly summaries of LLM research
   - Activity visualization for the selected week
   - Summaries of key developments
   - Highlight of the week

### Visualization (utils/plots.py)

- `plot_publication_counts()`: Line/bar chart of papers published
- `plot_activity_map()`: Calendar heatmap of publication activity
- `plot_weekly_activity_ts()`: Time series of weekly publication activity
- `plot_cluster_map()`: Scatter plot of paper topics using UMAP embeddings
- `plot_repos_by_feature()`: Bar chart of repositories by feature
- `plot_category_distribution()`: Horizontal bar chart of paper categories
- `plot_trending_words()`: Horizontal bar chart of trending words in paper titles

## Data Flow Overview

The core data (research papers, metadata) originates from arXiv and is processed by a separate system detailed in the [llmpedia_workflows repository](https://github.com/masta-g3/llmpedia_workflows). This workflow handles:
- Fetching new papers.
- Generating AI-derived content (summaries, artwork, insights).
- Performing topic modeling (e.g., using UMAP) and generating embeddings.
- Storing the raw and processed data into a PostgreSQL database.

This LLMpedia application primarily reads from that pre-populated database to display information through the Streamlit interface.

## Database Structure (Conceptual)

While the exact schema resides in the database managed by `llmpedia_workflows`, the application primarily interacts with tables representing:
- **Papers**: Core metadata (title, authors, abstract, arXiv ID, publication date), derived content (summaries, keywords), and links to generated assets (artwork).
- **Embeddings**: Vector representations of papers used for topic modeling and similarity searches.
- **Topics**: Clusters or categories derived from paper embeddings.
- **Repositories**: Information about related code repositories.
- **Tweets**: Relevant tweets associated with papers or topics (if applicable).
- **Logs**: Records of user activity or application events.

The `utils/db/db.py` module provides functions to query these conceptual entities.